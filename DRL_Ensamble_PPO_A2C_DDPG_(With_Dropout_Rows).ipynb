{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Iy2QC2RrhF",
        "outputId": "aad212bb-37b7-417b-f7ab-e51c833a5a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020'...\n",
            "remote: Enumerating objects: 758, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 758 (delta 0), reused 0 (delta 0), pack-reused 755\u001b[K\n",
            "Receiving objects: 100% (758/758), 37.53 MiB | 11.86 MiB/s, done.\n",
            "Resolving deltas: 100% (304/304), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NSCsdExEewW"
      },
      "source": [
        "Under folder /Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020, create a virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNQ7rB13ELQD",
        "outputId": "63b6db2d-e6aa-4d4b-c1d9-821ccbaca211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.11.3)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.8.0)\n",
            "Installing collected packages: platformdirs, distlib, virtualenv\n",
            "Successfully installed distlib-0.3.4 platformdirs-2.5.2 virtualenv-20.14.1\n"
          ]
        }
      ],
      "source": [
        "#Create virtual environment\n",
        "!pip install virtualenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBq4QAyEfvh"
      },
      "source": [
        "Create a virtualenv venv under folder /Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZdRavz6Eiux",
        "outputId": "d0fd6cfa-67b3-418a-85af-1895c4440462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created virtual environment CPython3.7.13.final.0-64 in 42133ms\n",
            "  creator CPython3Posix(dest=/content/drive/MyDrive/Semester_8_ShintaRH/RL_STOCK_CODES/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020-master/venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==22.0.4, setuptools==62.1.0, wheel==0.37.1\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!virtualenv -p python3 venv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZy_q6MeEnXt"
      },
      "source": [
        "To activate a virtualenv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjM_JyP4EpD6"
      },
      "outputs": [],
      "source": [
        "!source venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60fGmD2lI7L1",
        "outputId": "fc688ee1-b63a-4186-882e-13e79b325a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "backtesting.ipynb  \u001b[0m\u001b[01;34menv\u001b[0m/         \u001b[01;34mmodel\u001b[0m/            \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mconfig\u001b[0m/            \u001b[01;34mfigs\u001b[0m/        \u001b[01;34mpreprocessing\u001b[0m/    run_DRL.py\n",
            "\u001b[01;34mdata\u001b[0m/              __init__.py  README.md         \u001b[01;34mtrained_models\u001b[0m/\n",
            "done_data.csv      LICENSE      requirements.txt  \u001b[01;34mvenv\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tKgbrURuEy-_",
        "outputId": "362cbb35-40f6-45e5-94e4-dab3c56a14e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.16.4\n",
            "  Downloading numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 631 kB/s \n",
            "\u001b[?25hCollecting pandas==1.0.3\n",
            "  Downloading pandas-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (10.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0 MB 18.3 MB/s \n",
            "\u001b[?25hCollecting stockstats\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting scikit-learn==0.21.0\n",
            "  Downloading scikit_learn-0.21.0-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 26.6 MB/s \n",
            "\u001b[?25hCollecting gym==0.15.3\n",
            "  Downloading gym-0.15.3.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 31.6 MB/s \n",
            "\u001b[?25hCollecting stable-baselines[mpi]\n",
            "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 40 kB/s \n",
            "\u001b[?25hCollecting joblib==0.15.1\n",
            "  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.2.1\n",
            "  Downloading matplotlib-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 22.5 MB/s \n",
            "\u001b[?25hCollecting pytest<6.0.0,>=5.3.2\n",
            "  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 50.8 MB/s \n",
            "\u001b[?25hCollecting setuptools<42.0.0,>=41.4.0\n",
            "  Downloading setuptools-41.6.0-py2.py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting wheel<0.34.0,>=0.33.6\n",
            "  Downloading wheel-0.33.6-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2022.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.0->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (1.15.0)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 39.4 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.46.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 32.3 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (4.11.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (21.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (8.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (0.2.5)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (4.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.3->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements.txt (line 8)) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]->-r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]->-r requirements.txt (line 7)) (0.17.3)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 24.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym[atari,classic_control]>=0.11\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[K     |████████████████████████████████| 626 kB 46.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[K     |████████████████████████████████| 624 kB 44.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[K     |████████████████████████████████| 631 kB 35.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 46.3 MB/s \n",
            "\u001b[?25h  Downloading gym-0.20.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 36.2 MB/s \n",
            "\u001b[?25h  Downloading gym-0.19.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 32.6 MB/s \n",
            "\u001b[?25h  Downloading gym-0.18.3.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 45.7 MB/s \n",
            "\u001b[?25h  Downloading gym-0.18.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 47.0 MB/s \n",
            "\u001b[?25h  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 34.4 MB/s \n",
            "\u001b[?25h  Downloading gym-0.17.1.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 48.2 MB/s \n",
            "\u001b[?25h  Downloading gym-0.17.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 40.0 MB/s \n",
            "\u001b[?25h  Downloading gym-0.16.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 43.1 MB/s \n",
            "\u001b[?25h  Downloading gym-0.15.7.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 52.7 MB/s \n",
            "\u001b[?25h  Downloading gym-0.15.6.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 38.1 MB/s \n",
            "\u001b[?25h  Downloading gym-0.15.4.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: atari_py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (7.1.2)\n",
            "Building wheels for collected packages: gym, gast, mpi4py\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.3-py3-none-any.whl size=1644970 sha256=90d28cbbbc7949aa17f11b4a8fa4194d3a302bb768d740056c334f0f38771004\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/16/6b/2250ca4f9f050a4d27d8bed287e57bbb3c33fc4066f557cc75\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=5ea2528215ac6e74b737716944e3dd0f11cb8b7fd4e05ce2f881b944bc69cc04\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185270 sha256=9e786d50880b1feeb5a92284f3bd3b502767399e1d1e36cc0975f967f1b95054\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n",
            "Successfully built gym gast mpi4py\n",
            "Installing collected packages: numpy, pyglet, cloudpickle, gym, wheel, setuptools, pandas, matplotlib, joblib, tensorflow-estimator, tensorboard, stable-baselines, pluggy, mpi4py, keras-applications, gast, tensorflow, stockstats, scikit-learn, pytest\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.37.1\n",
            "    Uninstalling wheel-0.37.1:\n",
            "      Successfully uninstalled wheel-0.37.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.0 which is incompatible.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.16.4 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.16.4 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires cloudpickle>=1.3, but you have cloudpickle 1.2.2 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.4 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.4 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.4 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.4 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 1.0.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-1.2.2 gast-0.2.2 gym-0.15.3 joblib-0.15.1 keras-applications-1.0.8 matplotlib-3.2.1 mpi4py-3.1.3 numpy-1.16.4 pandas-1.0.3 pluggy-0.13.1 pyglet-1.3.2 pytest-5.4.3 scikit-learn-0.21.0 setuptools-41.6.0 stable-baselines-2.10.2 stockstats-0.4.1 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1 wheel-0.33.6\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXfpDYdEFiF6",
        "outputId": "7a8be742-a73e-4809-84dc-cbf338499302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n",
            "   datadate  ... turbulence\n",
            "0  20090102  ...        0.0\n",
            "1  20090102  ...        0.0\n",
            "2  20090102  ...        0.0\n",
            "3  20090102  ...        0.0\n",
            "4  20090102  ...        0.0\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "1053360\n",
            "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n",
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20151002\n",
            "======A2C Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:194: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/a2c/a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Training time (A2C):  2.11795414686203  minutes\n",
            "======A2C Validation from:  20151002 to  20160104\n",
            "A2C Sharpe Ratio:  0.03280948282158465\n",
            "======PPO Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "Training time (PPO):  6.857018784681956  minutes\n",
            "======PPO Validation from:  20151002 to  20160104\n",
            "PPO Sharpe Ratio:  0.07246914273279033\n",
            "======DDPG Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ddpg/policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ddpg/ddpg.py:94: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/ddpg/ddpg.py:444: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/stable_baselines/common/tf_util.py:432: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "Training time (DDPG):  1.135108188788096  minutes\n",
            "======DDPG Validation from:  20151002 to  20160104\n",
            "======Trading from:  20160104 to  20160405\n",
            "previous_total_asset:1000000\n",
            "end_total_asset:1095254.4901897884\n",
            "total_reward:95254.4901897884\n",
            "total_cost:  4278.669631203425\n",
            "total trades:  1391\n",
            "Sharpe:  0.35199742764651976\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20160104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.977122684319814  minutes\n",
            "======A2C Validation from:  20160104 to  20160405\n",
            "A2C Sharpe Ratio:  0.0363991705537898\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.70751500527064  minutes\n",
            "======PPO Validation from:  20160104 to  20160405\n",
            "PPO Sharpe Ratio:  0.1057575678696087\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.141621426741282  minutes\n",
            "======DDPG Validation from:  20160104 to  20160405\n",
            "======Trading from:  20160405 to  20160705\n",
            "previous_total_asset:1095254.4901897884\n",
            "end_total_asset:1100783.9004406973\n",
            "total_reward:5529.410250908928\n",
            "total_cost:  2218.1022909385083\n",
            "total trades:  976\n",
            "Sharpe:  0.02718434866391956\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20160405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.912893501917521  minutes\n",
            "======A2C Validation from:  20160405 to  20160705\n",
            "A2C Sharpe Ratio:  0.005786138485318875\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.556576263904572  minutes\n",
            "======PPO Validation from:  20160405 to  20160705\n",
            "PPO Sharpe Ratio:  0.1255712140795007\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1610334475835165  minutes\n",
            "======DDPG Validation from:  20160405 to  20160705\n",
            "======Trading from:  20160705 to  20161003\n",
            "previous_total_asset:1100783.9004406973\n",
            "end_total_asset:1114869.4466234485\n",
            "total_reward:14085.54618275119\n",
            "total_cost:  2650.2035718761413\n",
            "total trades:  1026\n",
            "Sharpe:  0.06559477791894132\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20160705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.9451950470606485  minutes\n",
            "======A2C Validation from:  20160705 to  20161003\n",
            "A2C Sharpe Ratio:  -0.0009236208969771498\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.813459567228953  minutes\n",
            "======PPO Validation from:  20160705 to  20161003\n",
            "PPO Sharpe Ratio:  -0.040482629279732084\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1505710363388062  minutes\n",
            "======DDPG Validation from:  20160705 to  20161003\n",
            "======Trading from:  20161003 to  20170103\n",
            "previous_total_asset:1114869.4466234485\n",
            "end_total_asset:1168598.75045371\n",
            "total_reward:53729.303830261575\n",
            "total_cost:  575.4308300899554\n",
            "total trades:  1200\n",
            "Sharpe:  0.21006128132621496\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20161003\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.9753507018089294  minutes\n",
            "======A2C Validation from:  20161003 to  20170103\n",
            "A2C Sharpe Ratio:  0.5652472857726026\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.855564785003662  minutes\n",
            "======PPO Validation from:  20161003 to  20170103\n",
            "PPO Sharpe Ratio:  0.2635496883144707\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1675904154777528  minutes\n",
            "======DDPG Validation from:  20161003 to  20170103\n",
            "======Trading from:  20170103 to  20170404\n",
            "previous_total_asset:1168598.75045371\n",
            "end_total_asset:1121317.5242913123\n",
            "total_reward:-47281.22616239777\n",
            "total_cost:  1798.7951265170686\n",
            "total trades:  1155\n",
            "Sharpe:  -0.2052007167577386\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20170103\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.9593534191449484  minutes\n",
            "======A2C Validation from:  20170103 to  20170404\n",
            "A2C Sharpe Ratio:  0.1330269520414573\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.818751891454061  minutes\n",
            "======PPO Validation from:  20170103 to  20170404\n",
            "PPO Sharpe Ratio:  0.25240711664574195\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1418090105056762  minutes\n",
            "======DDPG Validation from:  20170103 to  20170404\n",
            "======Trading from:  20170404 to  20170705\n",
            "previous_total_asset:1121317.5242913123\n",
            "end_total_asset:1163793.5474908468\n",
            "total_reward:42476.02319953451\n",
            "total_cost:  3009.337036162437\n",
            "total trades:  705\n",
            "Sharpe:  0.34883202913204014\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20170404\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.985297962029775  minutes\n",
            "======A2C Validation from:  20170404 to  20170705\n",
            "A2C Sharpe Ratio:  0.1584227128340343\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.7793668190638225  minutes\n",
            "======PPO Validation from:  20170404 to  20170705\n",
            "PPO Sharpe Ratio:  0.25779975992411597\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.147621754805247  minutes\n",
            "======DDPG Validation from:  20170404 to  20170705\n",
            "======Trading from:  20170705 to  20171003\n",
            "previous_total_asset:1163793.5474908468\n",
            "end_total_asset:1239792.7251292747\n",
            "total_reward:75999.17763842782\n",
            "total_cost:  6100.295174348886\n",
            "total trades:  1288\n",
            "Sharpe:  0.5520556462029661\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20170705\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.976064888636271  minutes\n",
            "======A2C Validation from:  20170705 to  20171003\n",
            "A2C Sharpe Ratio:  0.1881668487571232\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.788011415799459  minutes\n",
            "======PPO Validation from:  20170705 to  20171003\n",
            "PPO Sharpe Ratio:  0.17766739451873018\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1516481240590413  minutes\n",
            "======DDPG Validation from:  20170705 to  20171003\n",
            "======Trading from:  20171003 to  20180103\n",
            "previous_total_asset:1239792.7251292747\n",
            "end_total_asset:1368953.665984962\n",
            "total_reward:129160.94085568725\n",
            "total_cost:  4848.070720777364\n",
            "total trades:  1513\n",
            "Sharpe:  0.6905708557914878\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20171003\n",
            "======A2C Training========\n",
            "Training time (A2C):  2.0130239884058634  minutes\n",
            "======A2C Validation from:  20171003 to  20180103\n",
            "A2C Sharpe Ratio:  0.43162570145230095\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.900795372327169  minutes\n",
            "======PPO Validation from:  20171003 to  20180103\n",
            "PPO Sharpe Ratio:  0.40972244052587276\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1660810629526774  minutes\n",
            "======DDPG Validation from:  20171003 to  20180103\n",
            "======Trading from:  20180103 to  20180405\n",
            "previous_total_asset:1368953.665984962\n",
            "end_total_asset:1395283.7968666253\n",
            "total_reward:26330.130881663412\n",
            "total_cost:  1818.2866854695183\n",
            "total trades:  271\n",
            "Sharpe:  0.1100110870659573\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20180103\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.9965079108874002  minutes\n",
            "======A2C Validation from:  20180103 to  20180405\n",
            "A2C Sharpe Ratio:  0.008041559931045189\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.956969412167867  minutes\n",
            "======PPO Validation from:  20180103 to  20180405\n",
            "PPO Sharpe Ratio:  -0.0008930259415487093\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1621356884638467  minutes\n",
            "======DDPG Validation from:  20180103 to  20180405\n",
            "======Trading from:  20180405 to  20180705\n",
            "previous_total_asset:1395283.7968666253\n",
            "end_total_asset:1378434.4823040566\n",
            "total_reward:-16849.314562568674\n",
            "total_cost:  6201.14219835738\n",
            "total trades:  1073\n",
            "Sharpe:  -0.07013075533000962\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20180405\n",
            "======A2C Training========\n",
            "Training time (A2C):  2.013108225663503  minutes\n",
            "======A2C Validation from:  20180405 to  20180705\n",
            "A2C Sharpe Ratio:  -0.011697265197962492\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.836830917994181  minutes\n",
            "======PPO Validation from:  20180405 to  20180705\n",
            "PPO Sharpe Ratio:  -0.22996782536859411\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1726919809977214  minutes\n",
            "======DDPG Validation from:  20180405 to  20180705\n",
            "======Trading from:  20180705 to  20181003\n",
            "previous_total_asset:1378434.4823040566\n",
            "end_total_asset:1407499.1440714484\n",
            "total_reward:29064.66176739172\n",
            "total_cost:  5366.07730532162\n",
            "total trades:  723\n",
            "Sharpe:  0.25202465669598983\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20180705\n",
            "======A2C Training========\n",
            "Training time (A2C):  2.0130905469258624  minutes\n",
            "======A2C Validation from:  20180705 to  20181003\n",
            "A2C Sharpe Ratio:  0.043208443885316916\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.9305602033933  minutes\n",
            "======PPO Validation from:  20180705 to  20181003\n",
            "PPO Sharpe Ratio:  0.1834386515538365\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.2070896704991658  minutes\n",
            "======DDPG Validation from:  20180705 to  20181003\n",
            "======Trading from:  20181003 to  20190104\n",
            "previous_total_asset:1407499.1440714484\n",
            "end_total_asset:1413968.1903612746\n",
            "total_reward:6469.046289826278\n",
            "total_cost:  1067.2772982740505\n",
            "total trades:  120\n",
            "Sharpe:  0.11327099834557743\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20181003\n",
            "======A2C Training========\n",
            "Training time (A2C):  2.0416423161824544  minutes\n",
            "======A2C Validation from:  20181003 to  20190104\n",
            "A2C Sharpe Ratio:  -0.29455005337645745\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.834178654352824  minutes\n",
            "======PPO Validation from:  20181003 to  20190104\n",
            "PPO Sharpe Ratio:  -0.3789086521682244\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1430437882741293  minutes\n",
            "======DDPG Validation from:  20181003 to  20190104\n",
            "======Trading from:  20190104 to  20190405\n",
            "previous_total_asset:1413968.1903612746\n",
            "end_total_asset:1514647.8497566944\n",
            "total_reward:100679.65939541976\n",
            "total_cost:  6589.296732450397\n",
            "total trades:  1426\n",
            "Sharpe:  0.3701098868710062\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20190104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.998255157470703  minutes\n",
            "======A2C Validation from:  20190104 to  20190405\n",
            "A2C Sharpe Ratio:  0.09477114650952263\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.869838058948517  minutes\n",
            "======PPO Validation from:  20190104 to  20190405\n",
            "PPO Sharpe Ratio:  -0.08465153129716319\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1578128218650818  minutes\n",
            "======DDPG Validation from:  20190104 to  20190405\n",
            "======Trading from:  20190405 to  20190708\n",
            "previous_total_asset:1514647.8497566944\n",
            "end_total_asset:1521142.1085435227\n",
            "total_reward:6494.258786828257\n",
            "total_cost:  1076.0966742840671\n",
            "total trades:  159\n",
            "Sharpe:  0.2725785045108408\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20190405\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.9897788882255554  minutes\n",
            "======A2C Validation from:  20190405 to  20190708\n",
            "A2C Sharpe Ratio:  0.3098707657172304\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.750510434309642  minutes\n",
            "======PPO Validation from:  20190405 to  20190708\n",
            "PPO Sharpe Ratio:  0.44343033684117605\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.148310915629069  minutes\n",
            "======DDPG Validation from:  20190405 to  20190708\n",
            "======Trading from:  20190708 to  20191004\n",
            "previous_total_asset:1521142.1085435227\n",
            "end_total_asset:1518545.1409771373\n",
            "total_reward:-2596.9675663853996\n",
            "total_cost:  2030.1000528901734\n",
            "total trades:  352\n",
            "Sharpe:  -0.09271753259138994\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20190708\n",
            "======A2C Training========\n",
            "Training time (A2C):  2.0167741179466248  minutes\n",
            "======A2C Validation from:  20190708 to  20191004\n",
            "A2C Sharpe Ratio:  -0.20484306379165865\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.9046512564023335  minutes\n",
            "======PPO Validation from:  20190708 to  20191004\n",
            "PPO Sharpe Ratio:  -0.17834326732009828\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1609976689020793  minutes\n",
            "======DDPG Validation from:  20190708 to  20191004\n",
            "======Trading from:  20191004 to  20200106\n",
            "previous_total_asset:1518545.1409771373\n",
            "end_total_asset:1517625.165754234\n",
            "total_reward:-919.9752229033038\n",
            "total_cost:  256.1038435291672\n",
            "total trades:  40\n",
            "Sharpe:  -0.30115402046998885\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20191004\n",
            "======A2C Training========\n",
            "Training time (A2C):  2.00758714278539  minutes\n",
            "======A2C Validation from:  20191004 to  20200106\n",
            "A2C Sharpe Ratio:  -0.23974176177636305\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.8489822546641035  minutes\n",
            "======PPO Validation from:  20191004 to  20200106\n",
            "PPO Sharpe Ratio:  0.01482299729928126\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1410672426223756  minutes\n",
            "======DDPG Validation from:  20191004 to  20200106\n",
            "======Trading from:  20200106 to  20200406\n",
            "previous_total_asset:1517625.165754234\n",
            "end_total_asset:1497527.5922998148\n",
            "total_reward:-20097.57345441915\n",
            "total_cost:  1075.257702092552\n",
            "total trades:  178\n",
            "Sharpe:  -0.4538949507604217\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20200106\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.989976207415263  minutes\n",
            "======A2C Validation from:  20200106 to  20200406\n",
            "A2C Sharpe Ratio:  -0.3867990500895775\n",
            "======PPO Training========\n",
            "Training time (PPO):  6.825295595328013  minutes\n",
            "======PPO Validation from:  20200106 to  20200406\n",
            "PPO Sharpe Ratio:  -0.39756282475861043\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  1.1354707996050517  minutes\n",
            "======DDPG Validation from:  20200106 to  20200406\n",
            "======Trading from:  20200406 to  20200707\n",
            "previous_total_asset:1497527.5922998148\n",
            "end_total_asset:1501355.3292717764\n",
            "total_reward:3827.736971961567\n",
            "total_cost:  604.08015604599\n",
            "total trades:  103\n",
            "Sharpe:  0.23056419195033045\n",
            "Ensemble Strategy took:  180.88575803438823  minutes\n",
            "[3ade848bc2da:00838] *** Process received signal ***\n",
            "[3ade848bc2da:00838] Signal: Segmentation fault (11)\n",
            "[3ade848bc2da:00838] Signal code: Address not mapped (1)\n",
            "[3ade848bc2da:00838] Failing at address: 0x7fab8ae5e20d\n",
            "[3ade848bc2da:00838] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980)[0x7fab8d903980]\n",
            "[3ade848bc2da:00838] [ 1] /lib/x86_64-linux-gnu/libc.so.6(getenv+0xa5)[0x7fab8d542775]\n",
            "[3ade848bc2da:00838] [ 2] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(_ZN13TCMallocGuardD1Ev+0x34)[0x7fab8ddade44]\n",
            "[3ade848bc2da:00838] [ 3] /lib/x86_64-linux-gnu/libc.so.6(__cxa_finalize+0xf5)[0x7fab8d543605]\n",
            "[3ade848bc2da:00838] [ 4] /usr/lib/x86_64-linux-gnu/libtcmalloc.so.4(+0x13cb3)[0x7fab8ddabcb3]\n",
            "[3ade848bc2da:00838] *** End of error message ***\n"
          ]
        }
      ],
      "source": [
        "!python run_DRL.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMewJVJfLzJedl8HAwUnimC",
      "include_colab_link": true,
      "mount_file_id": "1nFJkciFUN-gJkhl_ZaxkKUu2uf5JKyGZ",
      "name": "SHINTA-DRL Ensamble PPO A2C DDPG (With Dropout Rows).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
